{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf600
{\fonttbl\f0\froman\fcharset0 Times-Roman;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red203\green209\blue214;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;\cssrgb\c83529\c85490\c87059;}
\margl1440\margr1440\vieww14200\viewh16580\viewkind0
\deftab720
\pard\pardeftab720\sl340\partightenfactor0

\f0\fs28 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3 Hi Julien,
\fs24 \
\pard\pardeftab720\sl280\partightenfactor0
\cf2 \
\pard\pardeftab720\sl340\partightenfactor0

\fs28 \cf2 A longer report after a weekend of work:
\fs24 \
\pard\pardeftab720\sl280\partightenfactor0
\cf2 \
\pard\pardeftab720\sl340\partightenfactor0

\fs28 \cf2 I spent quite some time on trying to create nn based rules. Most of my time I created networks that output a weight based on 4 pitches: if the pitches were part of the given melody, the weight was at the peak. I realized soon that the issue is to give bad examples, otherwise the network would simply rate everything at the peak weight. First I tried to generate a list of random pitches and classify them at the lowest weight, added to the list of good examples. In the good scenario it gave me a network that classified sequences as either good (at the peak) or bad (at the bottom), but it did not give a scale in any way. Several bad sequences (not included in the random examples) passed as good as well.
\fs24 \
\pard\pardeftab720\sl280\partightenfactor0
\cf2 \
\pard\pardeftab720\sl340\partightenfactor0

\fs28 \cf2 Next attempt I started to distort the good 4-pitch sequences and create a list of examples that I rated from perfect to less and less good. My scale had 4 steps, that indicated how many pitches were off. The output of this network did rate examples using the scale (even occasionally with more than 4 steps, but any example that was not included in the training data could be rated as perfect \'96 thus this was not that successful. I also created a constraint patch to generate pitch sequences using this network as a heuristic rule, hoping it would be able to somehow generate a fragment of the melody, but not very successful.
\fs24 \
\pard\pardeftab720\sl280\partightenfactor0
\cf2 \
\pard\pardeftab720\sl340\partightenfactor0

\fs28 \cf2 Finally, I regressed back to creating a network that simply predicted the 5th pitch, and then using this in rules (heuristic/strict). It was quite easy to recreate the melody this way. The heuristic version is close to what Jacopo used for his melodic distortion patches, but with the nn there is no set beginning, and if you through the sequence off, it might restart somewhere again (not necessary in the original order); I think it should be possible to create a constraint patch that generates fragments of the analyzed melody, between points where other rules take over. This might be interesting.
\fs24 \
\pard\pardeftab720\sl280\partightenfactor0
\cf2 \
\pard\pardeftab720\sl340\partightenfactor0

\fs28 \cf2 So to summarize: I find it unfortunately tricky to train the network to generate weights that are useful. If there is a way to do that, it would be the way to go.
\fs24 \
\pard\pardeftab720\sl280\partightenfactor0
\cf2 \
\pard\pardeftab720\sl340\partightenfactor0

\fs28 \cf2 I attach the two constraint patches and a trained neural network that is used for the rule. I coded your binary functions into lisp functions to be able to use them in the rule (see the codesnippet).
\fs24 \
\pard\pardeftab720\sl280\partightenfactor0
\cf2 \
\pard\pardeftab720\sl340\partightenfactor0

\fs28 \cf2 \'d6rjan}